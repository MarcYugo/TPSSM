{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Marc Yu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision.io.video import read_video\n",
    "\n",
    "occ_mask_thres = 0.05\n",
    "\n",
    "def flow_warp(x,\n",
    "              flow,\n",
    "              interpolation='bilinear',\n",
    "              padding_mode='zeros',\n",
    "              align_corners=True):\n",
    "    \"\"\"Warp an image or a feature map with optical flow.\n",
    "    Args:\n",
    "        x (Tensor): Tensor with size (n, c, h, w).\n",
    "        flow (Tensor): Tensor with size (n, h, w, 2). The last dimension is\n",
    "            a two-channel, denoting the width and height relative offsets.\n",
    "            Note that the values are not normalized to [-1, 1].\n",
    "        interpolation (str): Interpolation mode: 'nearest' or 'bilinear'.\n",
    "            Default: 'bilinear'.\n",
    "        padding_mode (str): Padding mode: 'zeros' or 'border' or 'reflection'.\n",
    "            Default: 'zeros'.\n",
    "        align_corners (bool): Whether align corners. Default: True.\n",
    "    Returns:\n",
    "        Tensor: Warped image or feature map.\n",
    "    \"\"\"\n",
    "    if x.size()[-2:] != flow.size()[1:3]:\n",
    "        raise ValueError(f'The spatial sizes of input ({x.size()[-2:]}) and '\n",
    "                         f'flow ({flow.size()[1:3]}) are not the same.')\n",
    "    _, _, h, w = x.size()\n",
    "    # create mesh grid\n",
    "    grid_y, grid_x = torch.meshgrid(torch.arange(0, h), torch.arange(0, w))\n",
    "    grid = torch.stack((grid_x, grid_y), 2).type_as(x)\n",
    "    grid.requires_grad = False\n",
    "\n",
    "    grid_flow = grid + flow\n",
    "    grid_flow_x = 2.0 * grid_flow[:, :, :, 0] / max(w - 1, 1) - 1.0\n",
    "    grid_flow_y = 2.0 * grid_flow[:, :, :, 1] / max(h - 1, 1) - 1.0\n",
    "    grid_flow = torch.stack((grid_flow_x, grid_flow_y), dim=3)\n",
    "    output = F.grid_sample(\n",
    "        x,\n",
    "        grid_flow,\n",
    "        mode=interpolation,\n",
    "        padding_mode=padding_mode,\n",
    "        align_corners=align_corners)\n",
    "\n",
    "    return output\n",
    "\n",
    "def get_occlusion_mask(flow, threshold=1.5):\n",
    "    # mean = torch.mean(flow, dim=(2,3), keepdim=True)\n",
    "    # std = torch.std(flow, dim=(2,3), keepdim=True)\n",
    "    # flow (n, h, w, 2)\n",
    "    mask = torch.mean(flow.abs(), dim=-1, keepdim=True) - threshold\n",
    "    mask = torch.clamp(mask, 0, 1)\n",
    "    mask = torch.sign(mask) # (n, h, w, 1)\n",
    "    mask = mask.permute(0, 3, 1, 2)\n",
    "    return mask\n",
    "\n",
    "def load_flow_tensor(path):\n",
    "    flow = torch.load(path)\n",
    "    flow = flow.permute(0,2,3,1)\n",
    "    return flow\n",
    "\n",
    "def pair_error(occ_mask_frm, frm1, frm2, flow_frm):\n",
    "    flow_warp_frm = flow_warp(frm2, flow_frm)\n",
    "    # print(occ_mask_frm.mean(), occ_mask_frm.max(), occ_mask_frm.min())\n",
    "    # assert 1==2\n",
    "    # error = occ_mask_frm * torch.abs((frm1 - flow_warp_frm)) #F.mse_loss(frm1, flow_warp_frm)\n",
    "    # error = F.mse_loss(occ_mask_frm*frm1, occ_mask_frm *flow_warp_frm) #, reduction='sum')\n",
    "    error = torch.sum((occ_mask_frm*frm1 - occ_mask_frm *flow_warp_frm)**2)\n",
    "    # error_sum = error.sum(dim=(1,2,3))\n",
    "    error = error/torch.sum(occ_mask_frm, dim=(1,2,3))\n",
    "    return error\n",
    "\n",
    "def warping_error_frames(frames, flow):\n",
    "    frm1 = frames[:1]\n",
    "    occ_masks = get_occlusion_mask(flow)\n",
    "    errors = []\n",
    "    pre_frm = frm1\n",
    "    for i in range(1, len(frames)):\n",
    "        frm = frames[i:i+1]\n",
    "        occ_mask = occ_masks[i-1:i]\n",
    "        flow_frm = flow[i-1:i]\n",
    "        frm_error1 = pair_error(occ_mask, frm, frm1, flow_frm)\n",
    "        frm_error2 = pair_error(occ_mask, frm, pre_frm, flow_frm)\n",
    "        # print('i=',i,'error1: ', frm_error1, 'error2: ', frm_error2)\n",
    "        errors.append(frm_error1+frm_error2)\n",
    "        pre_frm = frm\n",
    "    errors = torch.cat(errors, dim=0)\n",
    "    return errors\n",
    "\n",
    "def avg_warping_errors(errors):\n",
    "    m = errors.isnan()==False\n",
    "    errors = errors.nan_to_num()\n",
    "    avg = errors.sum()/m.sum()\n",
    "    return avg.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "back_flow_stem = load_flow_tensor('./out_flow/woman_running2_flow_stem_512_back.pt')\n",
    "back_flow_glfm = load_flow_tensor('./out_flow/woman_running2_flow_glfm_1.0_1.0_64_448_back.pt')\n",
    "back_flow_glfm2 = load_flow_tensor('./out_flow/woman_running2_flow_glfm_0.6_1.0_64_448_back.pt')\n",
    "back_flow_glfm3 = load_flow_tensor('./out_flow/woman_running2_flow_glfm_0.6_1.0_128_384_back.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Marc Yu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torchvision\\io\\video.py:161: UserWarning: The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\n",
      "  warnings.warn(\"The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\")\n"
     ]
    }
   ],
   "source": [
    "video_glfm, _, _ = read_video('./src_videos/tokenflow_PnP_fps_10_k1_64_k2_448_bs100_400frms_all_scale_1.0_type7.mp4', output_format='TCHW')\n",
    "video_stem, _, _ = read_video('./src_videos/tokenflow_PnP_fps_10_k512_bs100_400frms_type0.mp4', output_format='TCHW')\n",
    "video_glfm2, _, _ = read_video('./src_videos/tokenflow_PnP_fps_10_k1_64_k2_448_bs100_400frms_all_scale_0.6_type7.mp4', output_format='TCHW')\n",
    "video_glfm3, _, _ = read_video('./src_videos/tokenflow_PnP_fps_10_k1_128_k2_384_bs100_400frms_all_scale_0.6_type7.mp4', output_format='TCHW')\n",
    "\n",
    "video_glfm = video_glfm.float()/255.\n",
    "video_glfm2 = video_glfm2.float()/255.\n",
    "video_glfm2 = video_glfm3.float()/255.\n",
    "video_stem = video_stem.float()/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Marc Yu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:3527.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "stem_warping_errors = warping_error_frames(video_stem, back_flow_stem)\n",
    "glfm_warping_errors = warping_error_frames(video_glfm, back_flow_glfm)\n",
    "glfm_warping_errors2 = warping_error_frames(video_glfm2, back_flow_glfm2)\n",
    "glfm_warping_errors3 = warping_error_frames(video_glfm2, back_flow_glfm3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stem_warping_errors = stem_warping_errors.reshape(len(stem_warping_errors))\n",
    "glfm_warping_errors = glfm_warping_errors.reshape(len(glfm_warping_errors))\n",
    "glfm_warping_errors2 = glfm_warping_errors2.reshape(len(glfm_warping_errors2))\n",
    "glfm_warping_errors3 = glfm_warping_errors3.reshape(len(glfm_warping_errors3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glfm << k1=64,k2=448,α=1.0,β=1.0, average warping errors=  0.4913294017314911\n",
      "glfm << k1=64,k2=448,α=0.6,β=1.0, average warping errors=  0.4922697842121124\n",
      "glfm << k1=128,k2=384,α=0.6,β=1.0, average warping errors=  0.48882412910461426\n",
      "stem << k=512, average warping errors=  0.5161299109458923\n"
     ]
    }
   ],
   "source": [
    "print('glfm << k1=64,k2=448,α=1.0,β=1.0, average warping errors= ', avg_warping_errors(glfm_warping_errors))\n",
    "print('glfm << k1=64,k2=448,α=0.6,β=1.0, average warping errors= ', avg_warping_errors(glfm_warping_errors2))\n",
    "print('glfm << k1=128,k2=384,α=0.6,β=1.0, average warping errors= ', avg_warping_errors(glfm_warping_errors3))\n",
    "print('stem << k=512, average warping errors= ', avg_warping_errors(stem_warping_errors))\n",
    "\n",
    "del back_flow_stem\n",
    "del back_flow_glfm\n",
    "del back_flow_glfm2\n",
    "del back_flow_glfm3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Marc Yu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torchvision\\io\\video.py:161: UserWarning: The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\n",
      "  warnings.warn(\"The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\")\n",
      "C:\\Users\\Marc Yu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:3527.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glfm << k1=64,k2=192,α=0.6,β=1.0, average warping errors=  0.5476954579353333\n",
      "glfm << k1=64,k2=448,α=1.0,β=0.6, average warping errors=  0.6425002813339233\n"
     ]
    }
   ],
   "source": [
    "back_flow_glfm5 = load_flow_tensor('./out_flow/woman_running2_flow_glfm_0.6_1.0_64_192_back.pt')\n",
    "back_flow_glfm6 = load_flow_tensor('./out_flow/woman_running2_flow_glfm_1.0_0.6_64_448_back.pt')\n",
    "\n",
    "video_glfm5, _, _ = read_video('./src_videos/tokenflow_PnP_fps_10_k1_64_k2_192_bs100_400frms_all_scale_0.6_type7.mp4', output_format='TCHW')\n",
    "video_glfm6, _, _ = read_video('./src_videos/tokenflow_PnP_fps_10_k1_64_scale_1.0_k2_448_scale_0.6_bs100_400frms_type7.mp4', output_format='TCHW')\n",
    "video_glfm5 = video_glfm5.float()/255.\n",
    "video_glfm6 = video_glfm6.float()/255.\n",
    "\n",
    "glfm_warping_errors5 = warping_error_frames(video_glfm5, back_flow_glfm5)\n",
    "glfm_warping_errors6 = warping_error_frames(video_glfm6, back_flow_glfm6)\n",
    "del back_flow_glfm5\n",
    "del back_flow_glfm6\n",
    "glfm_warping_errors5.reshape(len(glfm_warping_errors5))\n",
    "glfm_warping_errors6.reshape(len(glfm_warping_errors6))\n",
    "\n",
    "print('glfm << k1=64,k2=192,α=0.6,β=1.0, average warping errors= ', avg_warping_errors(glfm_warping_errors5))\n",
    "print('glfm << k1=64,k2=448,α=1.0,β=0.6, average warping errors= ', avg_warping_errors(glfm_warping_errors6))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
